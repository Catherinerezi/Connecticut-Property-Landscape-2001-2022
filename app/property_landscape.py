# -*- coding: utf-8 -*-
"""AssignmentDay41_Chatharina.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dr6l4p9229QJFHYZtiSan3oeiyoVVjOe"""

from scipy.stats import norm
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.preprocessing import MinMaxScaler
import os
import tempfile, gdown
import streamlit as st
import csv
import requests

@st.cache_data(show_spinner=False)
def load_data_from_release() -> pd.DataFrame:
    url = "https://raw.githubusercontent.com/Catherinerezi/Connecticut-Property-Landscape-2001-2022/main/Real_Estate_Sales_2001-2022_GL(1).csv"
    df = pd.read_csv(url)
    return df

df = load_data_from_release()
st.dataframe(df)
st.set_page_config(page_title="Real Estate", layout="wide")

if not st.session_state.get("_go"):
    st.write("Klik **Mulai** untuk menjalankan analisis.")
    if st.button("Mulai"): st.session_state["_go"] = True
    else: st.stop()

df.head()

df.describe().T

df.shape

df.info()

df.duplicated().sum()

df.isnull().sum()

missing_percentage = df.isnull().sum()/df.shape[0]*100

cols_to_drop = df.columns[df.isnull().mean() > 0.2]
df = df.drop(columns=cols_to_drop)

missing_percentage = df.isnull().sum()/df.shape[0]*100

df['transaction_value'] = df['Sale Amount']

df[['Assessed Value', 'Sale Amount', 'transaction_value']].describe()

numeric_cols = df.select_dtypes(include=np.number).columns
numeric_cols = df.select_dtypes(include="number").columns
rows = []

for col in numeric_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower) | (df[col] > upper)]
    outlier_count = len(outliers)
    outlier_percentage = (outlier_count / len(df)) * 100

    rows.append({
        "Kolom": col, 
        "Jumlah Outlier": outlier_count, 
        "% Outlier": f"{outlier_percentage:.2f}%",
    })

outlier_df = pd.DataFrame(rows).sort_values("% Outlier", ascending=False)

df_safe = df.fillna("")

row_strings = df_safe.astype(str).agg(' '.join, axis=1)

pattern = r"(serial number|list year|date recorded|sale amount|address|assessed value|sales ratio)"
suspect_mask = row_strings.str.contains(pattern, case=False, regex=True)

suspect_rows = df[suspect_mask]
if suspect_rows.empty:
    st.success("Tidak ditemukan baris mencurigakan.")
else:
    st.dataframe(suspect_rows, use_container_width=True)

df_cleaned = df[~suspect_mask].copy()
df_cleaned.reset_index(drop=True, inplace=True)

row_strings_cleaned = df_cleaned.fillna("").astype(str).agg(' '.join, axis=1)

if "suspect_mask" not in locals():
    suspect_mask = df.fillna("").astype(str).agg(" ".join, axis=1).str.contains(
        r"(serial number|list year|date recorded|sale amount|address|assessed value|sales ratio)",
        case=False, regex=True
    )

df = df[~suspect_mask].reset_index(drop=True)

# Konversi kolom tanggal ke tipe datetime
df["Date Recorded"] = pd.to_datetime(df["Date Recorded"], errors='coerce')

df_clean = df.dropna(subset=["Serial Number","List Year","Date Recorded","Town","Address","Assessed Value","Sale Amount","Sales Ratio"])

df_clean = df.dropna()

df[["Date Recorded"]] = df[["Date Recorded"]].apply(pd.to_datetime, errors='coerce')

# Buat kolom baru dengan format Tahun
df["Year"] = pd.to_datetime(df["Date Recorded"], errors='coerce').dt.year

# Salin data awal lengkap tanpa kehilangan kolom apa pun
realestate_summary = df.copy()

#Buat kolom recency
realestate_summary['Date Recorded'] = pd.to_datetime(realestate_summary['Date Recorded'])
reference_date = realestate_summary['Date Recorded'].max()
realestate_summary['Data Recorded'] = (reference_date - realestate_summary['Date Recorded']).dt.days

# Agregasi per properti (berdasarkan alamat)
property_summary = df.groupby('Address').agg(
    town=('Town', 'first'),
    list_year=('List Year', 'min'),

    # Agregat total
    total_sale_amount=('Sale Amount', 'sum'),
    total_assessed_value=('Assessed Value', 'sum'),
    total_transactions=('Date Recorded', 'count'),

    # Agregat waktu
    first_recorded_date=('Date Recorded', 'min'),
    last_recorded_date=('Date Recorded', 'max'),

    # Rata-rata
    avg_sale_amount=('Sale Amount', 'mean'),
    avg_assessed_value=('Assessed Value', 'mean'),
    avg_sales_ratio=('Sales Ratio', 'mean')
).reset_index()

# Ambil kategori properti dominan per alamat
town_info = df.groupby('Address').agg(
    town=('Town', lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0])
).reset_index()

# Gabungkan ke ringkasan utama
property_summary = pd.merge(property_summary, town_info, on='Address', how='left')

# Kolom tambahan bulan pertama dan terakhir belanja (bentuk string)
property_summary['first_sale_month'] = property_summary['first_recorded_date'].dt.strftime('%b %Y')
property_summary['last_sale_month'] = property_summary['last_recorded_date'].dt.strftime('%b %Y')

latest_date = df['Date Recorded'].max()
property_summary['recency_days'] = (latest_date - property_summary['last_recorded_date']).dt.days

property_summary = property_summary.copy()

# Buat kategori harga properti
def categorize_price(x):
    if x < 500_000:
        return "< $500K"
    elif 500_000 <= x <= 1_000_000:
        return "$500K â€“ $1M"
    else:
        return "> $1M"

df["Price Category"] = df["Sale Amount"].apply(categorize_price)

# Hitung jumlah properti per kategori
price_counts = df["Price Category"].value_counts()

df_group = df.copy()
df_group["Price Category"] = df_group["Sale Amount"].apply(categorize_price)
df_top = df_group[df_group["Town"].isin(df_group["Town"].value_counts().head(min(5, df_group["Town"].nunique())).index)]

df_ready = df_clean.copy()

"""#Skoring RFM"""

property_summary[["recency_days","total_transactions","total_sale_amount"]] = \
    property_summary[["recency_days","total_transactions","total_sale_amount"]].apply(pd.to_numeric, errors="coerce")

# Skor RFM berdasarkan kuartil
property_summary["R_Score"] = pd.qcut(property_summary["recency_days"], 4, labels=[4,3,2,1], duplicates="drop").astype("Int64").fillna(2).astype(int)
property_summary["F_Score"] = pd.qcut(property_summary["total_transactions"].rank(method='first'), 4, labels=[1,2,3,4], duplicates="drop").astype("Int64").fillna(2).astype(int)
property_summary["M_Score"] = pd.qcut(property_summary["total_sale_amount"], 4, labels=[1,2,3,4], duplicates="drop").astype("Int64").fillna(2).astype(int)

# Gabungkan skor RFM
property_summary["RFM_Score"] = (
    property_summary["R_Score"].astype(str) +
    property_summary["F_Score"].astype(str) +
    property_summary["M_Score"].astype(str)
)

# Segmentasi
def label_segment(row):
    if row["R_Score"] == 4 and row["F_Score"] == 4 and row["M_Score"] == 4:
        return "Best"
    elif row["F_Score"] >= 3 and row["M_Score"] >= 3:
        return "Loyal"
    elif row["R_Score"] <= 2:
        return "At Risk"
    else:
        return "Others"

property_summary["RFM_Segment"] = property_summary.apply(label_segment, axis=1)

if "transaction_value" not in df.columns:
    df["transaction_value"] = df["Sale Amount"]

base_metrics = df.groupby('Address').agg({
    'Serial Number': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],
    'Sale Amount': ['sum', 'mean'],
    'Assessed Value': ['sum', 'mean'],
    'Sales Ratio': 'mean',
    'transaction_value': 'sum',
    'Date Recorded': ['min', 'max'],
    'List Year': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
}).reset_index()

# Rapikan nama kolom dari hasil multi-aggregasi
base_metrics.columns = ['Address',
    'Serial Number',
    'Sale Amount_sum', 'Sale Amount_mean',
    'Assessed Value_sum', 'Assessed Value_mean',
    'Sales Ratio_mean',
    'transaction_value_sum',
    'Date Recorded_min', 'Date Recorded_max',
    'List Year_mode'
]

property_summary = pd.merge(property_summary, base_metrics, on='Address', how='left')

property_summary.columns

# Membandingkan 2 kolom Address dan Serial Number
df[['Address', 'Serial Number']].drop_duplicates().head()

"""#1. Bagaimana distribusi properti berdasarkan skor RFM, dan segmen mana yang paling mendominasi dalam portofolio properti saat ini?"""

fig, ax = plt.subplots(figsize=(8,5))
sns.countplot(data=property_summary, x="RFM_Segment", order=property_summary["RFM_Segment"].value_counts().index, palette="Set2")
ax.set_title("Distribusi Properti Berdasarkan Segmentasi RFM")
ax.set_xlabel("RFM Segment")
ax.set_ylabel("Jumlah Properti")
fig.tight_layout()
st.pyplot()

"""#2. Bagaimana tren rata-rata harga jual properti dari tahun ke tahun, dan apakah terdapat pola yang dapat menginformasikan keputusan investasi atau pengembangan ke depan?
"""

fig, ax = plt.subplots(figsize=(8,5))
yearly_avg = df.groupby("Year")["Sale Amount"].mean()
sns.lineplot(x=yearly_avg.index, y=yearly_avg.values)
ax.set_title("Tren Rata-rata Harga Properti per Tahun")
ax.set_xlabel("Tahun")
ax.set_ylabel("Rata-rata Sale Amount")
ax.set_ylim(bottom=0)
fig.tight_layout()
st.pyplot()

"""#3. Kota mana saja yang memiliki volume transaksi properti tertinggi, dan bagaimana persebarannya menunjukkan potensi atau dinamika pasar?
"""

fig, ax = plt.subplots(figsize=(8,5))
top_towns = df["Town"].value_counts().head(10)
sns.barplot(x=top_towns.values, y=top_towns.index, palette="viridis")
ax.set_title("10 Kota dengan Jumlah Transaksi Tertinggi")
ax.set_xlabel("Jumlah Transaksi")
ax.set_ylabel("Kota")
fig.tight_layout()
st.pyplot()

"""#4. Stacked Bar Harga Jual
"""

pivot = df_top.pivot_table(index="Town", columns="Price Category", values="Serial Number", aggfunc="count")
fig, ax = plt.subplots(figsize=(8,5))
pivot.plot(kind="bar", stacked=True, colormap="Set2", ax=ax)
ax.set_title("Distribusi Kategori Harga Properti per Kota (Top 5)")
ax.set_ylabel("Jumlah Properti")
fig.tight_layout()
st.pyplot()

"""#5. Apakah terdapat hubungan kuat antara harga jual dengan nilai asesmen dan sales ratio, yang dapat digunakan sebagai indikator valuasi atau strategi harga properti?
"""

fig, ax = plt.subplots(figsize=(7, 3))
numeric_cols = ['Sale Amount', 'Assessed Value', 'Sales Ratio']
corr = df[numeric_cols].corr()
sns.heatmap(
    corr,
    annot=True,
    cmap='coolwarm',
    fmt=".2f",
    vmin=-1,  # Batas bawah skala korelasi
    vmax=1    # Batas atas skala korelasi
)
ax.set_title("Heatmap Korelasi antar Variabel Numerik")
fig.tight_layout()
st.pyplot()

csv_bytes = property_summary.to_csv(index=False).encode("utf-8")  # atau df.to_csv(...)
st.download_button(
    label="Download property_summary.csv",
    data=csv_bytes,
    file_name="property_summary.csv",
    mime="text/csv",
)
